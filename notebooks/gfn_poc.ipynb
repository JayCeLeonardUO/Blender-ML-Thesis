{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcmc is for later\n",
    "# from pyro.infer.mcmc import MCMC\n",
    "armature = {\"nothing\": 0}\n",
    "\n",
    "primitve_shapes = {\n",
    "    \"triangle\": 3,\n",
    "    \"point\": 1,\n",
    "    \"quad\": 4,\n",
    "    \"triangle_strip\": 3,\n",
    "}\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "\n",
    "def compose_mesh(dx: list):\n",
    "    print(dx)\n",
    "    return dx\n",
    "\n",
    "\n",
    "def is_blade_of_grass(mesh):\n",
    "    print(mesh)\n",
    "    if reduce(lambda x, y: x * y, map(lambda x: primitve_shapes[x], mesh)) < 12:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "# this means that this will generate plolygons with proparty 2X as much\n",
    "def reward(mesh):\n",
    "    if is_blade_of_grass(mesh):\n",
    "        return 10\n",
    "    if \"triangle_strip\" in mesh:\n",
    "        return 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['triangle', 'triangle_strip']\n",
      "['triangle', 'triangle_strip']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dx = [\"triangle\", \"triangle_strip\"]\n",
    "reward(compose_mesh(test_dx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow Network\n",
    "- The goal of the flow network will be to generate examples *proportional* to `reward`\n",
    "- the net in GflowNet refers to an MDP\n",
    "- 'input_dims'\n",
    "    - For choosing in this `primitve_shapes` example there are $4$ *patches*\n",
    "> not sure if `source` and`sink` have to be a defined composition. or can by any composition with a given property that it finds\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\"\"\"\n",
    "A neural network model class that inherits from `torch.nn.Module`.\n",
    "\n",
    "Attributes:\n",
    "-----------\n",
    "mlp : torch.nn\n",
    "    A multi-layer perceptron (MLP) neural network.\n",
    "\n",
    "Methods:\n",
    "--------\n",
    "__init__(hid_dim: int) -> None\n",
    "    Initializes the flowModdel class with a hidden dimension size.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class FlowModel(nn.Module):\n",
    "    def __init__(self, hid_dim, input_dim: int) -> None:\n",
    "        super().__init__()\n",
    "        # input_dim:int of possable actions\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, hid_dim), nn.LeakyReLU(), nn.Linear(hid_dim, input_dim)\n",
    "        )\n",
    "    def forward(self,x)->any:\n",
    "        # flow must be positive o\n",
    "\n",
    "        # unclear to me how x contains this information\n",
    "        # ... \n",
    "        # and multiply by (1 - x) to give 0 flow to actions we know we can't take\n",
    "        # (in this case, x[i] is 1 if a feature is already there, so we know we\n",
    "        # can't add it again)\n",
    "        # ...\n",
    "\n",
    "        # in the paper this is F\n",
    "        return self.mlp(x).exp() * (1-x)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sum_{s: (s,s')\\in\\mathcal{E}} F(s,s') = R(s') + \\sum_{s'':(s',s'')\\in\\mathcal{E}} F(s',s'')$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "def face_parents(state: List[str]) -> Tuple[List[List[str]], List[int]]:\n",
    "    \"\"\"\n",
    "    Find parent states and their corresponding actions for a given state.\n",
    "    \n",
    "    Args:\n",
    "        state: Current state represented as a list of face parts\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (parent_states, parent_actions) where:\n",
    "        - parent_states is a list of states, each missing one face part\n",
    "        - parent_actions is a list of indices corresponding to the removed parts\n",
    "    \"\"\"\n",
    "    # Create parent states by removing one face part at a time\n",
    "    parent_states = [[part for part in state if part != face_part] \n",
    "                    for face_part in state]\n",
    "    \n",
    "    # Sort the state to create sorted_keys\n",
    "    sorted_keys = sorted(state)\n",
    "    \n",
    "    # Find the action index for each removed face part\n",
    "    parent_actions = [sorted_keys.index(face_part) \n",
    "                     for face_part in state]\n",
    "    \n",
    "    return parent_states, parent_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train for Experiment\n",
    "\n",
    "1. Set up `mlflow` : from `./notebooks` dir run\n",
    "    ``` bash\n",
    "    # im useing poatry so\n",
    "    $ poetry run mlflow ui\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|         | 0/50000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state: [],\n",
      " Sorted keys: {'triangle': 3, 'point': 1, 'quad': 4, 'triangle_strip': 3},\n",
      " State: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "tensor(1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# \"Go\" to the next state\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent state: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Sorted keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msorted_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m State: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m new_state \u001b[38;5;241m=\u001b[39m state \u001b[38;5;241m+\u001b[39m [\u001b[43msorted_keys\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction\u001b[49m\u001b[43m]\u001b[49m]\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Now we want to compute the loss, we'll first enumerate the parents\u001b[39;00m\n\u001b[1;32m     42\u001b[0m parent_states, parent_actions \u001b[38;5;241m=\u001b[39m face_parents(new_state)\n",
      "\u001b[0;31mKeyError\u001b[0m: tensor(1)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from mlflow import log_metric, log_param, log_artifacts\n",
    "import tqdm\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.distributions.categorical import Categorical\n",
    "\n",
    "# import duckdb\n",
    "sorted_keys = primitve_shapes\n",
    "\n",
    "\n",
    "def face_to_tensor(face):\n",
    "    assert(False)\n",
    "    return torch.tensor([i in face for i in primitve_shapes]).float()\n",
    "\n",
    "\n",
    "# Instantiate model and optimizer\n",
    "F_sa = FlowModel(hid_dim=512, input_dim=len(primitve_shapes))\n",
    "opt = Adam(F_sa.parameters(), 3e-4)\n",
    "\n",
    "# Let's keep track of the losses and the faces we sample\n",
    "losses = []\n",
    "sampled_faces = []\n",
    "# To not complicate the code, I'll just accumulate losses here and take a\n",
    "# gradient step every `update_freq` episode.\n",
    "minibatch_loss = 0\n",
    "update_freq = 4\n",
    "for episode in tqdm.tqdm(range(50000), ncols=40):\n",
    "    # Each episode starts with an \"empty state\"\n",
    "    state = []\n",
    "    # Predict F(s, a)\n",
    "    edge_flow_prediction = F_sa(face_to_tensor(state))\n",
    "    for t in range(3):\n",
    "        # The policy is just normalizing, and gives us the probability of each action\n",
    "        policy = edge_flow_prediction / edge_flow_prediction.sum()\n",
    "        # Sample the action\n",
    "        action = Categorical(probs=policy).sample()\n",
    "        # \"Go\" to the next state\n",
    "        print(f\"Current state: {state},\\n Sorted keys: {sorted_keys},\\n State: {state}\")\n",
    "        new_state = state + [sorted_keys[action]]\n",
    "\n",
    "        # Now we want to compute the loss, we'll first enumerate the parents\n",
    "        parent_states, parent_actions = face_parents(new_state)\n",
    "        # And compute the edge flows F(s, a) of each parent\n",
    "        px = torch.stack([face_to_tensor(p) for p in parent_states])\n",
    "        pa = torch.tensor(parent_actions).long()\n",
    "        parent_edge_flow_preds = F_sa(px)[torch.arange(len(parent_states)), pa]\n",
    "        # Now we need to compute the reward and F(s, a) of the current state,\n",
    "        # which is currently `new_state`\n",
    "        if t == 2:\n",
    "            # If we've built a complete face, we're done, so the reward is > 0\n",
    "            # (unless the face is invalid)\n",
    "            reward = reward(new_state)\n",
    "            # and since there are no children to this state F(s,a) = 0 \\forall a\n",
    "            edge_flow_prediction = torch.zeros(6)\n",
    "        else:\n",
    "            # Otherwise we keep going, and compute F(s, a)\n",
    "            reward = 0\n",
    "            edge_flow_prediction = F_sa(face_to_tensor(new_state))\n",
    "\n",
    "        # The loss as per the equation above\n",
    "        flow_mismatch = (\n",
    "            parent_edge_flow_preds.sum() - edge_flow_prediction.sum() - reward\n",
    "        ).pow(2)\n",
    "        minibatch_loss += flow_mismatch  # Accumulate\n",
    "        # Continue iterating\n",
    "        state = new_state\n",
    "\n",
    "    # We're done with the episode, add the face to the list, and if we are at an\n",
    "    # update episode, take a gradient step.\n",
    "    sampled_faces.append(state)\n",
    "    if episode % update_freq == 0:\n",
    "        losses.append(minibatch_loss.item())\n",
    "        minibatch_loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        minibatch_loss = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
